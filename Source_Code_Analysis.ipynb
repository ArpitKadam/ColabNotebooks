{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArpitKadam/ColabNotebooks/blob/main/Source_Code_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain chromadb tiktoken\n",
        "!pip install -q langchain_core langchain_community\n",
        "!pip install -q langchain-chroma langchain-text-splitters\n",
        "!pip install -q unstructured\n",
        "!pip install -q esprima pdfminer\n",
        "!pip install -q langchain_groq\n",
        "!pip install -q GitPython\n",
        "!pip install langchain_ollama ollama"
      ],
      "metadata": {
        "id": "CnHrLHR4b_1U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "044241f5-0d96-4c17-85e1-44c63bfbd73b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.7/21.7 MB\u001b[0m \u001b[31m123.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m135.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m220.0/220.0 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m139.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-adk 1.20.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.39.1 which is incompatible.\n",
            "google-adk 1.20.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-gcp-logging 1.11.0a0 requires opentelemetry-sdk<1.39.0,>=1.35.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m476.0/476.0 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "google-adk 1.20.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.39.1 which is incompatible.\n",
            "google-adk 1.20.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
            "opentelemetry-exporter-gcp-logging 1.11.0a0 requires opentelemetry-sdk<1.39.0,>=1.35.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m608.4/608.4 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m167.8/167.8 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.9/207.9 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m328.2/328.2 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m47.0/47.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for esprima (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pdfminer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m137.5/137.5 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain_ollama\n",
            "  Downloading langchain_ollama-1.0.1-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting ollama\n",
            "  Downloading ollama-0.6.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain_ollama) (1.2.1)\n",
            "Requirement already satisfied: httpx>=0.27 in /usr/local/lib/python3.12/dist-packages (from ollama) (0.28.1)\n",
            "Requirement already satisfied: pydantic>=2.9 in /usr/local/lib/python3.12/dist-packages (from ollama) (2.12.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27->ollama) (4.12.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27->ollama) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27->ollama) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27->ollama) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27->ollama) (0.16.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_ollama) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_ollama) (0.4.58)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_ollama) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_ollama) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_ollama) (9.1.2)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_ollama) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.0.0->langchain_ollama) (0.12.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9->ollama) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9->ollama) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9->ollama) (0.4.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.0.0->langchain_ollama) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_ollama) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_ollama) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_ollama) (2.32.5)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_ollama) (0.25.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_ollama) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.0.0->langchain_ollama) (2.3.0)\n",
            "Downloading langchain_ollama-1.0.1-py3-none-any.whl (29 kB)\n",
            "Downloading ollama-0.6.1-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: ollama, langchain_ollama\n",
            "Successfully installed langchain_ollama-1.0.1 ollama-0.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Markdown\n",
        "from git import Repo\n",
        "from langchain_text_splitters import Language\n",
        "from langchain_community.document_loaders.generic import GenericLoader\n",
        "from langchain_community.document_loaders.parsers import LanguageParser\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_groq import ChatGroq\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from pathlib import Path\n",
        "from langchain_ollama import OllamaEmbeddings\n",
        "from langchain_community.vectorstores.utils import filter_complex_metadata\n",
        "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
        "from langchain_community.document_loaders import TextLoader, UnstructuredImageLoader, UnstructuredHTMLLoader\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain_core.chat_history import InMemoryChatMessageHistory"
      ],
      "metadata": {
        "id": "xxQzzr1DezMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "os.environ['GROQ_API_KEY'] = userdata.get('GROQ_API_KEY')"
      ],
      "metadata": {
        "id": "AGZwy598hxpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir test_repo"
      ],
      "metadata": {
        "id": "OCdGAop0nH7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repo_path = \"/content/test_repo\"\n",
        "repo = Repo.clone_from(\"https://github.com/ArpitKadam/DocuXment-App\", to_path=repo_path)"
      ],
      "metadata": {
        "id": "q9wTg8NgnM7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "python_loader = GenericLoader.from_filesystem(\n",
        "    repo_path,\n",
        "    glob=\"**/*\",\n",
        "    suffixes=[\".py\"],\n",
        "    parser=LanguageParser(language=Language.PYTHON, parser_threshold=100)\n",
        ")"
      ],
      "metadata": {
        "id": "sydjd6iEezFI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_loader = GenericLoader.from_filesystem(\n",
        "    repo_path,\n",
        "    glob=\"**/*.txt\"\n",
        ")"
      ],
      "metadata": {
        "id": "9LlJSJnEb_yz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for path in Path(repo_path).rglob(\"*.md\"):\n",
        "    markdown_loader = UnstructuredMarkdownLoader(path)"
      ],
      "metadata": {
        "id": "lE1J7kE9W_Zz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for path in Path(repo_path).rglob(\"*.log\"):\n",
        "    log_loader = TextLoader(path)"
      ],
      "metadata": {
        "id": "wVHBirszYa42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for path in Path(repo_path).rglob(\"*.html\"):\n",
        "  html_loader = UnstructuredHTMLLoader(path, mode=\"elements\")"
      ],
      "metadata": {
        "id": "p3JcxKQAXusd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "js_loader = GenericLoader.from_filesystem(\n",
        "    repo_path,\n",
        "    glob=\"**/*\",\n",
        "    suffixes=[\".js\"],\n",
        "    parser=LanguageParser(language=Language.JS, parser_threshold=100)\n",
        ")"
      ],
      "metadata": {
        "id": "AQl2eKFvbkT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "documents = python_loader.load() + text_loader.load() + markdown_loader.load() + log_loader.load() + html_loader.load() + js_loader.load()"
      ],
      "metadata": {
        "id": "kGIlCOCuUFS9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(documents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59r7JpT2W7bS",
        "outputId": "791fb8ae-4664-48f6-d097-21104645c0c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Markdown(documents[6].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 743
        },
        "id": "ES5C2N0QYCPS",
        "outputId": "e6c247d1-6f46-4ede-8bf8-0aea2bd4e6c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "def classify_question_complexity(question):\n    \"\"\"Enhanced question complexity classification for competition optimization\"\"\"\n    question_lower = question.lower()\n    \n    # High complexity indicators\n    high_complexity_indicators = [\n        \"compare\", \"analyze\", \"relationship\", \"interaction\", \"simultaneously\", \n        \"while\", \"also request\", \"also ask\", \"both\", \"multiple\", \"various\", \"different\",\n        \"scenario\", \"interaction\", \"contrast\", \"evaluate\"\n    ]\n    \n    # Medium complexity indicators  \n    medium_complexity_indicators = [\n        \"covered\", \"eligible\", \"benefit\", \"claim\", \"waiting period\", \"exclusion\",\n        \"limitation\", \"condition\", \"procedure\", \"process\", \"requirement\"\n    ]\n    \n    # Simple question indicators\n    simple_indicators = [\"what is\", \"define\", \"meaning\", \"who is\", \"when\", \"where\"]\n    \n    # Calculate complexity score\n    complexity_score = 0\n    complexity_score += sum(1 for indicator in high_complexity_indicators if indicator in question_lower)\n    complexity_score += len([char for char in question if char == \"?\"]) - 1  # Multiple questions\n    complexity_score += question.count(\",\") // 2  # Multiple clauses\n    complexity_score += question.count(\" and \") + question.count(\" or \")  # Logical operators\n    \n    # Length-based complexity\n    if len(question.split()) > 25:\n        complexity_score += 2\n    elif len(question.split()) > 15:\n        complexity_score += 1\n    \n    # Determine final complexity\n    if complexity_score >= 4:\n        return \"complex\"\n    elif complexity_score >= 2 or any(indicator in question_lower for indicator in medium_complexity_indicators):\n        return \"medium\"\n    elif any(indicator in question_lower for indicator in simple_indicators):\n        return \"simple\"\n    else:\n        return \"medium\""
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for d in documents[:5]:\n",
        "    print(d.metadata)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V--irtq7cBxT",
        "outputId": "698a92de-e903-4eb2-a5fe-362aff46610a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'source': '/content/test_repo/api.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>}\n",
            "{'source': '/content/test_repo/api.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>}\n",
            "{'source': '/content/test_repo/api.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>}\n",
            "{'source': '/content/test_repo/api.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>}\n",
            "{'source': '/content/test_repo/api.py', 'content_type': 'functions_classes', 'language': <Language.PYTHON: 'python'>}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import (\n",
        "    RecursiveCharacterTextSplitter,\n",
        "    Language,\n",
        "    RecursiveCharacterTextSplitter\n",
        ")\n",
        "\n",
        "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
        "    language=Language.PYTHON,\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200\n",
        ")\n",
        "\n",
        "js_splitter = RecursiveCharacterTextSplitter.from_language(\n",
        "    language=Language.JS,\n",
        "    chunk_size=600,\n",
        "    chunk_overlap=100\n",
        ")\n",
        "\n",
        "markdown_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=800,\n",
        "    chunk_overlap=200,\n",
        "    separators=[\"\\n## \", \"\\n### \", \"\\n\\n\", \"\\n\", \" \"]\n",
        ")\n",
        "\n",
        "log_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=300,\n",
        "    chunk_overlap=100,\n",
        "    separators=[\"\\n\", \" \"]\n",
        ")\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,\n",
        "    chunk_overlap=100\n",
        ")"
      ],
      "metadata": {
        "id": "8VasbPKNcBA3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_docs = []\n",
        "\n",
        "for doc in documents:\n",
        "  ext = doc.metadata['source'].split(\".\")[-1].lower()\n",
        "\n",
        "  if ext == \"py\":\n",
        "    split_docs.extend(python_splitter.split_documents([doc]))\n",
        "\n",
        "  elif ext == \"js\":\n",
        "    split_docs.extend(js_splitter.split_documents([doc]))\n",
        "\n",
        "  elif ext in [\".md\", \".html\", \".htm\"]:\n",
        "    split_docs.extend(markdown_splitter.split_documents([doc]))\n",
        "\n",
        "  elif ext == \".log\":\n",
        "    split_docs.extend(log_splitter.split_documents([doc]))\n",
        "\n",
        "  else:\n",
        "    split_docs.extend(text_splitter.split_documents([doc]))"
      ],
      "metadata": {
        "id": "t4C4fGt4X6pm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Before:\", len(documents))\n",
        "print(\"After:\", len(split_docs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55KsBBS1gczb",
        "outputId": "86ae4ecc-a98e-4cc5-fb1b-4d24097eadc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before: 66\n",
            "After: 135\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_docs = filter_complex_metadata(split_docs)"
      ],
      "metadata": {
        "id": "uw8m8Ft2nO3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Before:\", len(documents))\n",
        "print(\"After:\", len(split_docs))\n",
        "print(\"After Cleaning:\", len(clean_docs))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3LYwSV_nTpW",
        "outputId": "f1f8f5de-ce95-4cbf-8a15-30b755e869a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before: 66\n",
            "After: 135\n",
            "After Cleaning: 135\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OllamaEmbeddings(\n",
        "  model=\"embeddinggemma\"\n",
        ")\n",
        "\n",
        "llm = ChatGroq(\n",
        "    model=\"openai/gpt-oss-20b\"\n",
        ")"
      ],
      "metadata": {
        "id": "7U5DqbW2xRia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_db = Chroma.from_documents(\n",
        "    documents=clean_docs,\n",
        "    embedding=embeddings,\n",
        "    persist_directory=\"db\"\n",
        ")"
      ],
      "metadata": {
        "id": "4UO9-kUfg6hm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vector_db.as_retriever(\n",
        "    search_type=\"mmr\",\n",
        "    search_kwargs={\"k\": 5}\n",
        ")"
      ],
      "metadata": {
        "id": "UJMKwdsfg6fO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever.invoke(\"HTTPBearer\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "j_iQd1TppzgB",
        "outputId": "5327b863-6298-45d1-da66-a3637ed97c29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(id='6a176ee2-c469-4283-ad82-cefc15abfe20', metadata={'element_id': '54ed4443a2b2b983bd1b5e402e7151ad', 'source': '/content/test_repo/templates/index.html', 'filename': 'index.html', 'parent_id': '4407651d967591e0ea5895ca6025b300', 'filetype': 'text/html', 'category_depth': 2, 'last_modified': '2025-12-16T10:52:53', 'file_directory': '/content/test_repo/templates', 'category': 'Title'}, page_content='Sources'),\n",
              " Document(id='2e56fed5-3d67-45f3-919d-05939a84b675', metadata={'parent_id': '7945d65501b4b04706b5679364dadc34', 'filename': 'index.html', 'category': 'UncategorizedText', 'filetype': 'text/html', 'source': '/content/test_repo/templates/index.html', 'element_id': 'e9b77d8e7252d0fe1453851350cac46e', 'file_directory': '/content/test_repo/templates', 'last_modified': '2025-12-16T10:52:53'}, page_content='{{ message }}'),\n",
              " Document(id='e49f4f40-e85b-44c5-8ec4-68259bf9c593', metadata={'category_depth': 1, 'parent_id': '6a498e027f0d909e8574ef91fbe5d6ac', 'file_directory': '/content/test_repo/templates', 'last_modified': '2025-12-16T10:52:53', 'filename': 'index.html', 'source': '/content/test_repo/templates/index.html', 'filetype': 'text/html', 'element_id': '7945d65501b4b04706b5679364dadc34', 'category': 'Title'}, page_content='File Preview'),\n",
              " Document(id='d3202fb1-c63c-4c5a-a381-d36343630bd5', metadata={'source': '/content/test_repo/README.md'}, page_content='[![License: Proprietary](https://img.shields.io/badge/License-Proprietary-red.svg)](LICENSE.md) [![Python Version](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/downloads/) [![Framework: FastAPI](https://img.shields.io/badge/Framework-FastAPI-green.svg)](https://fastapi.tiangolo.com/) [![Framework: Flask](https://img.shields.io/badge/Framework-Flask-blue.svg)](https://flask.palletsprojects.com/) [![GitHub'),\n",
              " Document(id='dcdf14c7-7c59-4d3f-bab2-798950f8f9e3', metadata={'source': '/content/test_repo/api.py', 'content_type': 'functions_classes', 'language': 'python'}, page_content='def verify_api_key(creds: HTTPAuthorizationCredentials = Security(auth_scheme)):\\n    if not AUTH_TOKEN or creds.credentials != AUTH_TOKEN:\\n        raise HTTPException(status_code=401, detail=\"Invalid API key\")\\n    return creds.credentials')]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = ChatPromptTemplate.from_messages([\n",
        "      (\n",
        "        \"system\",\n",
        "        \"\"\"\n",
        "        You are an expert Source Code Analyzer and Software Architect.\n",
        "\n",
        "        Your role:\n",
        "        - Analyze source code, configuration files, documentation, and logs.\n",
        "        - Explain functionality, architecture, control flow, and dependencies.\n",
        "        - Identify key files, functions, classes, and modules.\n",
        "        - Reason strictly from the provided context (retrieved code chunks).\n",
        "        - If information is missing, say so explicitly â€” do NOT hallucinate.\n",
        "\n",
        "        Guidelines:\n",
        "        - Prefer precise, technical explanations.\n",
        "        - Reference filenames, paths, or functions when available.\n",
        "        - For â€œhow it worksâ€ questions, explain step-by-step execution flow.\n",
        "        - For â€œwhyâ€ questions, infer intent only if supported by code or docs.\n",
        "        - For debugging questions, point to exact lines or modules responsible.\n",
        "        - For summaries, group by components or layers (API, service, utils, config).\n",
        "        - Keep answers concise but technically complete.\n",
        "        \"\"\"\n",
        "      ),\n",
        "\n",
        "      # Conversational memory\n",
        "      MessagesPlaceholder(variable_name=\"history\"),\n",
        "\n",
        "      (\n",
        "        \"human\",\n",
        "        \"\"\"\n",
        "        Retrieved Context (source code & docs):\n",
        "        {context}\n",
        "\n",
        "        User Question:\n",
        "        {input}\n",
        "        \"\"\"\n",
        "      )\n",
        "])\n"
      ],
      "metadata": {
        "id": "Bn2jY_68qloe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain = (\n",
        "    {\n",
        "        # Extract ONLY the user query for retrieval\n",
        "        \"context\": RunnableLambda(lambda x: x[\"input\"]) | retriever,\n",
        "\n",
        "        # Pass user input to the prompt\n",
        "        \"input\": RunnableLambda(lambda x: x[\"input\"]),\n",
        "\n",
        "        # ğŸ”‘ PASS HISTORY THROUGH\n",
        "        \"history\": RunnableLambda(lambda x: x[\"history\"]),\n",
        "    }\n",
        "    | prompt\n",
        "    | llm\n",
        ")\n"
      ],
      "metadata": {
        "id": "0DUAFDMyrU08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store = {}\n",
        "\n",
        "def get_session_history(session_id: str):\n",
        "    if session_id not in store:\n",
        "        store[session_id] = InMemoryChatMessageHistory()\n",
        "    return store[session_id]\n"
      ],
      "metadata": {
        "id": "bLsWMXXkrUyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain_with_memory = RunnableWithMessageHistory(\n",
        "    rag_chain,\n",
        "    get_session_history,\n",
        "    input_messages_key=\"input\",\n",
        "    history_messages_key=\"history\",\n",
        ")"
      ],
      "metadata": {
        "id": "QQSrn_EvrUvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hLar_cbd1xWb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config={\"configurable\": {\"session_id\": \"user-2\"}}"
      ],
      "metadata": {
        "id": "OZMsyQT-1uQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = rag_chain_with_memory.invoke(\n",
        "    {\"input\": \"What is the purpose of function build_faiss_for_urls\"},\n",
        "    config=config\n",
        ")\n",
        "\n",
        "Markdown(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 923
        },
        "id": "lnfPexQxrUtF",
        "outputId": "5bdb7386-8d5b-4004-bf16-648f07a68efd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Purpose of `build_faiss_for_urls`**\n\nThe `build_faiss_for_urls` function is a helper that takes a list of URLs, downloads or fetches the content at those URLs, and then creates a FAISS (Facebook AI Similarity Search) vectorâ€‘store index from that content.  \n\nIn short, it turns arbitrary web resources into a searchable vector database that can later be queried with embeddings.\n\n**Highâ€‘level workflow**\n\n1. **Iterate over the supplied URLs**  \n   ```python\n   for link in urls:\n   ```\n\n2. **Determine the MIME type (optional)**  \n   It sends a `HEAD` request to the URL to inspect the `Contentâ€‘Type` header.  \n   ```python\n   head = requests.head(link, allow_redirects=True, timeout=10)\n   ctype = (head.headers.get(\"Content-Type\") or \"\").lower()\n   ```\n   This can be used to decide how to load the file (e.g., PDF, text, image).\n\n3. **Identify file extension**  \n   ```python\n   ext = Path(urlparse(link).path).suffix.lower()\n   ```\n   The extension (`.pdf`, `.txt`, `.jpg`, etc.) is used to pick an appropriate loader.\n\n4. **Download or load the content**  \n   Depending on the MIME type and extension, the function would:\n   * Use `PyPDFLoader` for PDFs,\n   * Use `requests` or `urllib` to fetch HTML/text,\n   * Use `pytesseract` for images (OCR),\n   * Or any other loader available in the project.\n\n5. **Create a `Document` object**  \n   The fetched content is wrapped in a `langchain_core.documents.Document` instance, which includes metadata such as the URL, file type, and raw text.\n\n6. **Split the text into chunks**  \n   A `RecursiveCharacterTextSplitter` (imported in `api.py`) would break the raw text into smaller, manageable pieces suitable for embeddings.\n\n7. **Generate embeddings**  \n   Using `NVIDIAEmbeddings` (or another embedding provider), each chunk is converted into a dense vector.\n\n8. **Store vectors in FAISS**  \n   The vectors are added to a `langchain_community.vectorstores.FAISS` instance, producing an inâ€‘memory similarity search index.\n\n9. **Return or expose the FAISS index**  \n   The function finally returns the FAISS object (or stores it globally) so that downstream API endpoints can query it.\n\n**Why this is useful**\n\n- **Unified search**: By turning disparate web resources into a single vector index, you can run semantic queries across all of them.\n- **Scalability**: FAISS is highly optimized for fast nearestâ€‘neighbor search on large embeddings collections.\n- **Modularity**: The function separates the concerns of fetching data and building the index, making the rest of the codebase cleaner.\n\n**Missing details**\n\nThe snippet provided stops after determining the file extension. The full implementation would include the steps above (loading, splitting, embedding, indexing). If you need the exact code for those steps, the rest of the `flask_app.py` file (or a helper module) would contain them."
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0bu_udyg08j9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}